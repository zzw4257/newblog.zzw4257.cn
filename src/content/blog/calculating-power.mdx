---
title: 算力杂谈：从微观算子到宏观架构
description: 深度解析2026年算力格局，从RTX 5090、H200到Apple M4 Max的架构差异，以及底层FLOPs与内存墙的本质探讨。
pubDate: 2026-01-26T10:00:00
author: zzw4257
image: /images/compute-2026.jpg
categories:
  - Hardware
  - AI Infrastructure
tags: ["GPU", "LLM", "CUDA", "HPC"]
badge: DeepDive
---

在 2026 年的今天，当我们谈论“组装一台电脑”时，我们实际上是在谈论如何构建一个微型的 AI 基础设施。

作为一名 AI 工程师或研究者，对算力的理解不能仅停留在显卡型号上。从底层的 MACs 计算到宏观的互联架构，每一个环节都决定了你是被“内存墙”撞得头破血流，还是能丝滑地跑通那个 70B 的模型。

本文基于最新的硬件格局，重新梳理算力体系。

## 核心格局：众神殿 (The Pantheon of Compute)

首先，让我们看清当前的战场。这不仅仅是参数的堆砌，而是不同技术路线对 **LLM（大语言模型）** 和 **RL（强化学习）** 需求的差异化响应。

<div className="w-full overflow-x-auto my-8 shadow-lg rounded-lg border border-gray-200 dark:border-gray-700">
  <table className="w-full text-sm text-left text-gray-500 dark:text-gray-400">
    <thead className="text-xs text-gray-700 uppercase bg-gray-50 dark:bg-gray-700 dark:text-gray-400">
      <tr>
        <th scope="col" className="px-6 py-3 whitespace-nowrap">特性参数</th>
        <th scope="col" className="px-6 py-3 bg-blue-50 dark:bg-blue-900/20 text-blue-600 dark:text-blue-400 font-bold border-l-4 border-blue-500">RTX 5090 <span className="block text-xs font-normal text-gray-500">Consumer Flagship</span></th>
        <th scope="col" className="px-6 py-3">RTX 4090</th>
        <th scope="col" className="px-6 py-3 bg-green-50 dark:bg-green-900/20 text-green-600 dark:text-green-400 font-bold border-l-4 border-green-500">NVIDIA H200 <span className="block text-xs font-normal text-gray-500">The King</span></th>
        <th scope="col" className="px-6 py-3">NVIDIA A800</th>
        <th scope="col" className="px-6 py-3 bg-purple-50 dark:bg-purple-900/20 text-purple-600 dark:text-purple-400 font-bold border-l-4 border-purple-500">Apple M4 Max <span className="block text-xs font-normal text-gray-500">Unified Memory</span></th>
      </tr>
    </thead>
    <tbody>
      <tr className="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
        <th scope="row" className="px-6 py-4 font-medium text-gray-900 whitespace-nowrap dark:text-white">架构</th>
        <td className="px-6 py-4 bg-blue-50/50 dark:bg-blue-900/10 font-semibold">Blackwell (SM 12.0)</td>
        <td className="px-6 py-4">Ada Lovelace (SM 8.9)</td>
        <td className="px-6 py-4 bg-green-50/50 dark:bg-green-900/10 font-semibold">Hopper (SM 9.0)</td>
        <td className="px-6 py-4">Ampere (SM 8.0)</td>
        <td className="px-6 py-4 bg-purple-50/50 dark:bg-purple-900/10 font-semibold">Apple Silicon</td>
      </tr>
      <tr className="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
        <th scope="row" className="px-6 py-4 font-medium text-gray-900 whitespace-nowrap dark:text-white">显存带宽<br/><span className="text-xs text-red-500">Key Bottleneck</span></th>
        <td className="px-6 py-4 bg-blue-50/50 dark:bg-blue-900/10 font-bold text-lg">1,792 GB/s <span className="text-xs text-green-500 block">▲78% vs 4090</span></td>
        <td className="px-6 py-4">1,008 GB/s</td>
        <td className="px-6 py-4 bg-green-50/50 dark:bg-green-900/10 font-bold text-lg">4,800 GB/s <span className="text-xs text-gray-500 block">HBM3e</span></td>
        <td className="px-6 py-4">2,039 GB/s</td>
        <td className="px-6 py-4 bg-purple-50/50 dark:bg-purple-900/10">546 GB/s</td>
      </tr>
      <tr className="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
        <th scope="row" className="px-6 py-4 font-medium text-gray-900 whitespace-nowrap dark:text-white">显存容量</th>
        <td className="px-6 py-4 bg-blue-50/50 dark:bg-blue-900/10">32 GB (GDDR7)</td>
        <td className="px-6 py-4">24 GB (GDDR6X)</td>
        <td className="px-6 py-4 bg-green-50/50 dark:bg-green-900/10 font-bold">141 GB (HBM3e)</td>
        <td className="px-6 py-4">80 GB (HBM2e)</td>
        <td className="px-6 py-4 bg-purple-50/50 dark:bg-purple-900/10 font-bold">Up to 128 GB (Unified)</td>
      </tr>
      <tr className="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
        <th scope="row" className="px-6 py-4 font-medium text-gray-900 whitespace-nowrap dark:text-white">互联技术</th>
        <td className="px-6 py-4 bg-blue-50/50 dark:bg-blue-900/10 text-red-500">PCIe Only</td>
        <td className="px-6 py-4 text-red-500">PCIe Only</td>
        <td className="px-6 py-4 bg-green-50/50 dark:bg-green-900/10 text-green-600">NVLink (900 GB/s)</td>
        <td className="px-6 py-4 text-yellow-600">NVLink (400 GB/s)</td>
        <td className="px-6 py-4 bg-purple-50/50 dark:bg-purple-900/10 text-red-500">N/A</td>
      </tr>
      <tr className="bg-gray-50 border-b dark:bg-gray-900 dark:border-gray-700">
        <th scope="row" className="px-6 py-4 font-medium text-gray-900 dark:text-white">RL & LLM 核心差异</th>
        <td className="px-6 py-4 bg-blue-50/50 dark:bg-blue-900/10 text-sm">
          <strong>FP4/FP6 硬件支持</strong>是亮点，推理速度将有质变。显存增加到 32GB 缓解了量化焦虑，但无 NVLink 依然是多卡训练的死穴。
        </td>
        <td className="px-6 py-4 text-sm">
          <strong>性价比守门员</strong>。FP32 强劲，适合 Isaac Gym 仿真，但带宽已成大模型瓶颈。
        </td>
        <td className="px-6 py-4 bg-green-50/50 dark:bg-green-900/10 text-sm">
          <strong>唯一的真神</strong>。4.8TB/s 带宽 + 141GB 显存，单卡即可运行不量化的 Llama-3-70B，且吞吐量惊人。
        </td>
        <td className="px-6 py-4 text-sm">
          <strong>特供版痛点</strong>：NVLink 带宽被阉割 (600->400)，大规模集群通信效率下降，但单卡微调依旧强于消费卡。
        </td>
        <td className="px-6 py-4 bg-purple-50/50 dark:bg-purple-900/10 text-sm">
          <strong>推理/能效之王</strong>。运行超大模型成本最低的方案，但缺乏 CUDA 生态，不适合训练和 RL 仿真。
        </td>
      </tr>
    </tbody>
  </table>
</div>

### 关键解读

1.  **带宽即正义 (Memory Wall)**：
    LLM 推理本质上是 Memory Bound（受限于显存带宽）而非 Compute Bound（受限于算力）。
    * **RTX 5090** 的 GDDR7 将带宽拉到了 **1,792 GB/s**，这比 4090 提升了近 80%，这意味着 Token 生成速度将有肉眼可见的飞跃。
    * **H200** 的 **4.8 TB/s** 是真正的生产力工具，它解决了“计算核心在等数据搬运”的尴尬。

2.  **显存类型的代际差异**：
    * **HBM (High Bandwidth Memory)**：如同在芯片旁边盖摩天大楼，位宽极高（H200 为 6144-bit）。
    * **GDDR**：如同在芯片旁边铺高速公路，靠高频跑车（28 Gbps）。
    * **LPDDR (Apple)**：靠极低延迟和统一内存架构（UMA）取胜，让 CPU 和 GPU 共享海量内存（128GB），这是 NVIDIA 消费级显卡（32GB/24GB）目前无法逾越的鸿沟。

---

## 算力的微观视角：FLOPs vs MACs

在评估模型计算量时，我们常被这两个单位搞混。根据 `FLOPs_MACs.ipynb` 的笔记，我们需要明确定义：

> **FLOPs (Floating Point Operations)**: 浮点运算次数。一次加法或一次乘法都算 1 FLOP。
> **MACs (Multiply-Accumulate Operations)**: 乘加运算。$a \leftarrow a + (b \times c)$。

现代硬件（如 Tensor Cores）通常使用 FMA（Fused Multiply-Add）指令，一个时钟周期完成一次乘加。

$$
\text{1 MAC} = 2 \text{ FLOPs}
$$

**计算公式速查：**

* **全连接层 (Linear Layer)**:
    对于输入 $N$，输出 $M$：
    $$ \text{FLOPs} = 2 \times N \times M $$
    *(注：$2$ 代表一次乘法和一次加法)*

* **卷积层 (Conv2d)**:
    $$ \text{FLOPs} = 2 \times (H_{out} \times W_{out}) \times C_{in} \times K^2 \times C_{out} $$
    这解释了为什么图像生成（AIGC）如此消耗算力——输出特征图的每一个像素都需要经过完整的核运算。

**注意区分大小写**：
* **FLOPs** (s 小写): 运算**总量** (Count)。
* **FLOPS** (S 大写): 运算**速度** (Per Second)。

---

## 算力的系统视角：木桶效应

算力不仅仅是 GPU 的独角戏。从我们对 `主板.ipynb`, `内存.ipynb`, `硬盘.ipynb` 的研究中，可以得出以下构建 AI Infra 的铁律：

### 1. CPU：主仆关系
CPU 不是 GPU 的附庸，而是**主人**。
* **PCIe Lane**: 所有的 GPU 都是通过 PCIe 插槽连接到 CPU 的。使用 `lscpu` 和 `lspci` 可以查看这种拓扑。
* **AMD EPYC vs Intel Xeon**: 在多卡系统中，PCIe 通道数量至关重要。EPYC 通常提供更多的 PCIe Lanes，适合多卡并行（如 8卡 4090 炼丹炉）。

### 2. 内存：带宽计算
内存带宽不仅影响 CPU 性能，也影响数据加载到 GPU 的速度（DataLoader 瓶颈）。
* **公式**: $\text{带宽} = \text{频率} \times \text{位宽} / 8$
* **M4 Max 的秘密**: 它的内存位宽高达 **512-bit** (LPDDR5X-8533)，计算如下：
    $$ 8533 \times 512 / 8 / 1000 \approx 546 \text{ GB/s} $$
    这个带宽是普通双通道 DDR5 PC 内存（约 80-100 GB/s）的 **5-6 倍**。这就是为什么 Mac 跑大模型推理快的原因——它喂数据的勺子比 PC 大得多。

### 3. 存储与外设：细节决定成败
* **NVMe**: 在大规模训练中，Checkpoints 的保存和数据集的读取是高并发 IO。必须使用 NVMe SSD。
* **电源 (PSU)**: `硬件与组机.ipynb` 提到，家用电通常限制在 10A 或 16A。
    * **RTX 5090 功耗 600W**。双卡工作站极易触碰家用电路 2200W (10A) 的上限，甚至需要熔断器或空调插座 (16A)。
    * 计算公式：$P = U \times I$。

---

## 实用工具箱 (Linux)

在服务器端排查算力瓶颈时，这些命令比 GUI 更可靠：

```bash
# 查看主板与插槽占用 (分辨是否插在 PCIe x16 上)
sudo dmidecode -t slot

# 查看 CPU 拓扑
lscpu

# 查看内存配置 (是否插满通道)
sudo dmidecode -t memory

# 查看硬盘健康与型号 (区分 NVMe 与 SATA)
sudo smartctl -i /dev/nvme0n1
lsblk
```