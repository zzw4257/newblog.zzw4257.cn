---
title: 人工智能前沿：机器学习与深度学习核心概念
description: 本文系统梳理了机器学习的基本概念、监督/无监督学习、损失函数、经验风险与期望风险、神经网络基础、反向传播算法等核心内容，是 ACEE 人工智能前沿课程的考试复习笔记。
pubDate: 2025-10-15T12:00:00.000Z
image: /images/uploads/curricular-frontiers-of-artificial-intelligence-ai-front-cover.jpg
badge: Course
draft: false
categories:
  - AIGC
  - Course Notes
tags:
  - 机器学习
  - 深度学习
  - 神经网络
  - 反向传播
  - ACEE
  - 课程笔记
---

> **[迁移说明]** 本文最初发布于 `blog.zzw4257.cn`，现已迁移并在本站进行结构化整理与增强。

# 人工智能前沿 (Frontiers of Artificial Intelligence) - 考试笔记

## 第三章: 机器学习与深度学习 (Chapter 3: Machine Learning and Deep Learning)

---

### 一、机器学习基本概念 (Basic Concepts of Machine Learning)

> **核心思想 (Core Idea)**  
> 机器学习通过对数据的优化学习，建立能够刻画数据中所蕴含语义概念或分布结构等信息的模型。  
> (Machine learning, through optimized learning from data, establishes models capable of characterizing semantic concepts or distributional structures inherent in the data.)
> 
> - **模型学习过程 (Model Learning Process):** 利用有标签数据 (labeled data) 或无标签数据 (unlabeled data)，对模型参数不断进行优化，从而提升模型性能。

#### 1. 机器学习：概念与分类 (Machine Learning: Concepts and Classification)

* **从数据利用的角度 (From the perspective of data utilization):**
  * **监督学习 (Supervised Learning):**
    * 学习从输入 `x` 到输出 `y` 的映射 `f`。
    * 训练数据包含标签: $D = \{(x_i, y_i)\}_{i=1}^N$
    * `x_i`: 文档 (document), 图像 (image), 音频 (audio), 蛋白质基因 (protein/gene sequences) 等。
    * `y_i`: 论文类别 (paper category), 人脸对象 (face identity), 歌曲语音 (song/speech), 生命功能 (life function) 等语义内容。
    * 目标: 从假设空间 (hypothesis space) 学习得到一个最优映射函数 $f$ (决策函数 - decision function)。
    * 例子:
      * 图像数据 -> 类别分类 (Person, Dog, ...)
      * 文本数据 -> 情感分类 (喜悦, 愤怒, ...)
  * **无监督学习 (Unsupervised Learning):**
    * 训练数据无标签: $\{x_i\}_{i=1}^N$
    * 目标: 发现数据中的结构、模式或表示。
  * **半监督学习 (Semi-supervised Learning):**
    * 训练数据部分有标签，部分无标签。

#### 2. 有监督学习：训练集、验证集、测试集 (Supervised Learning: Training, Validation, Test Sets)

* **数据划分 (Data Splitting):**
  * **训练集 (Training Set):** 用于模型参数优化 (model parameter optimization)。
    * *好比学生的练习册 (Like a student's exercise book).*
  * **验证集 (Validation Set):** 用于挑选更好的模型参数 (hyperparameter tuning) 和模型选择 (model selection)。
    * *好比学生的模拟考卷或小测验 (Like a student's mock exam or quiz).*
  * **测试集 (Test Set):** 用于对最终模型的性能进行测试评估 (final model performance evaluation)。
    * *好比真正考试 (Like the actual exam).*
> **⚠️ 重要原则 (Crucial Principle)**  
> 训练集、验证集和测试集所包含数据之间**没有任何交叉 (no overlap)**。
* **常见比例 (Common Ratios):** e.g., 80% 训练 / 10% 验证 / 10% 测试; 或 70% / 15% / 15%.

#### 3. 模型评估与参数估计手段：损失函数 (Model Evaluation and Parameter Estimation: Loss Function)

* **泛化能力 (Generalization Ability):**
  * 模型在训练集上取得的性能与在测试集上取得的性能保持一致。
  * (The model's ability to perform consistently well on both training data and unseen test data.)
* **损失函数 (Loss Function):** $Loss(f(x_i), y_i)$
  * 用以估量预测值 $\hat{y}_i = f(x_i)$ 和真实值 $y_i$ 之间的差异。
  * 训练目标: $\min \sum_{i=1}^{N} Loss(f(x_i), y_i)$
* **常见损失函数 (Common Loss Functions) (表 4.1):**
  * **0-1 损失函数 (0-1 Loss):**
    $$
    Loss(y_i, f(x_i)) = \begin{cases} 1, & f(x_i) \neq y_i \\ 0, & f(x_i) = y_i \end{cases}
    $$
  * **平方损失函数 (Square Loss):**
    $$
    Loss(y_i, f(x_i)) = (y_i - f(x_i))^2
    $$
  * **绝对损失函数 (Absolute Loss):**
    $$
    Loss(y_i, f(x_i)) = |y_i - f(x_i)|
    $$
  * **对数损失函数 / 交叉熵损失 (Log Loss / Cross-Entropy Loss):**
    $$
    Loss(y_i, P(y_i|x_i)) = -\log P(y_i|x_i)
    $$

    (Often $P(y_i|x_i)$ is the model's predicted probability for the true class $y_i$)

#### 4. 经验风险与期望风险 (Empirical Risk and Expected Risk)

* **经验风险 (Empirical Risk, $\Re_{emp}$):** 模型在训练集上的平均损失。
  $$
  \Re_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N} Loss(y_i, f(x_i))
  $$

  * 经验风险越小，模型对训练数据拟合程度越好。
* **期望风险 (Expected Risk, $\Re$):** 模型关于联合分布 $P(x,y)$ 的期望损失 (真实风险或真实误差)。
  $$
  \Re(f) = E_{P(x,y)}[Loss(y, f(x))] = \int \int Loss(y, f(x)) P(x,y) dx dy
  $$

  * 目标是最小化期望风险，但 $P(x,y)$ 通常未知。

#### 5. 经验风险最小化 (Empirical Risk Minimization, ERM)

* 由于无法直接计算期望风险，通常用经验风险最小化作为替代。
* **关系 (Relationship):** $\Re \le \Re_{emp} + err$
  * `err` (误差项) 取决于模型复杂度和训练样本数量。
* **过学习 (Overfitting):**
  * 模型过于复杂，导致 $\Re_{emp}$ 很低，但 `err` 很大，进而期望风险 $\Re$ 较高。
  * 模型在训练集上表现好，但在测试集上表现差。

#### 6. 模型泛化能力、经验风险和期望风险之间关系 (Relationship between Generalization, Empirical Risk, and Expected Risk)

* **结构风险最小化 (Structural Risk Minimization, SRM):**
  * 为了防止过学习，引入正则化项来降低模型复杂度。
  * 目标: $\min_f \left( \frac{1}{N} \sum_{i=1}^{N} Loss(y_i, f(x_i)) + \lambda J(f) \right)$
    * $J(f)$: 正则化因子 (regularizer) 或惩罚项 (penalty term)，表示模型复杂度。
    * $\lambda$: 调整惩罚强度的系数。
* **奥卡姆剃刀 (Occam's Razor):** "如无必要，勿增实体" (Entities should not be multiplied without necessity) -> "简单有效原理" (Simple and effective principle).
  * 老子《道德经》: "万物之始，大道至简，衍化至繁。"

#### 7. 模型度量方法 (Model Evaluation Metrics) - (二分类问题为例 - For binary classification)

* **基本术语 (Basic Terms):**

  * `P` (Positive): 正例总数
  * `N` (Negative): 负例总数
  * `TP` (True Positive): 真正例 (正确预测为正)
  * `FP` (False Positive): 假正例 (错误预测为正，Type I error)
  * `TN` (True Negative): 真反例 (正确预测为负)
  * `FN` (False Negative): 假反例 (错误预测为负，Type II error)
* **指标 (Metrics):**

  * **准确率 (Accuracy):**
    $$
    ACC = \frac{TP + TN}{P + N} = \frac{TP + TN}{TP + FP + TN + FN}
    $$

    * !!! warning "注意"
      如果正负样本比例不平衡 (imbalanced data)，ACC 不是一个好的度量方法。
  * **错误率 (Error Rate):**
    $$
    ErrorRate = \frac{FP + FN}{P + N} = 1 - ACC
    $$
  * **精确率 (Precision) / 查准率:** 模型预测为正例的样本中，实际为正例的比例。
    $$
    Precision = \frac{TP}{TP + FP}
    $$
  * **召回率 (Recall) / 查全率:** 实际为正例的样本中，被模型正确预测为正例的比例。
    $$
    Recall = \frac{TP}{TP + FN}
    $$
  * **F1-score:** 精确率和召回率的调和平均数 (harmonic mean)。
    $$
    F1 = \frac{2 \times Precision \times Recall}{Precision + Recall} = \frac{2TP}{2TP + FP + FN}
    $$

    * 综合考虑 Precision 和 Recall，当两者差异较小时 F1 值较高。

---

### 二、回归分析 (Regression Analysis)

#### 1. 基本概念与线性回归 (Basic Concepts and Linear Regression)

* **回归分析 (Regression Analysis):** 分析若干变量之间的关系。
* **回归模型 (Regression Model):** 刻画不同变量之间关系的模型。
* **例子 (Galton's Height Regression):** $y = 33.73 (\text{英寸}) + 0.516x$
  * $y$: 子女平均身高, $x$: 父母平均身高。
  * "衰退 (regression)" 现象：向均值回归。
  * "线性回归"名称保留至今。
* **参数学习 (Parameter Learning):** 模型中的参数需要从标注数据中学习得到 (监督学习)。

#### 2. 一元线性回归模型 (Univariate Linear Regression Model)

* **模型 (Model):** $y = ax + b$
* **目标 (Goal):** 寻找一条直线，使其尽可能靠近或穿过所有数据点 $(x_i, y_i)$。
* **最小二乘法 (Least Squares Method):**
  * 使得残差平方和 (sum of squared residuals) 最小。残差 (residual) = 预测值 - 真实值。
  * 最小化: $L(a,b) = \sum_{i=1}^{N} (y_i - (ax_i + b))^2$
* **参数求解 (Parameter Estimation):**
  * 对 $L(a,b)$ 分别对 $a$ 和 $b$ 求偏导，并令其为零。
  * $\frac{\partial L}{\partial b} = \sum 2(y_i - ax_i - b)(-1) = 0 \Rightarrow \sum y_i - a \sum x_i - Nb = 0$
    $$
    \Rightarrow N\bar{y} - aN\bar{x} - Nb = 0 \Rightarrow b = \bar{y} - a\bar{x}
    $$

    (where $\bar{y}$ is the mean of y, $\bar{x}$ is the mean of x)
  * $\frac{\partial L}{\partial a} = \sum 2(y_i - ax_i - b)(-x_i) = 0 \Rightarrow \sum (y_i x_i - ax_i^2 - bx_i) = 0$
    Substitute $b = \bar{y} - a\bar{x}$:
    $$
    a = \frac{\sum_{i=1}^{N} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{N} (x_i - \bar{x})^2} = \frac{\sum x_i y_i - N\bar{x}\bar{y}}{\sum x_i^2 - N\bar{x}^2}
    $$

    (The slide shows a slightly different form, $a = \frac{x_1y_1 + \dots + x_8y_8 - 8\bar{x}\bar{y}}{x_1^2 + \dots + x_8^2 - 8\bar{x}^2}$ for N=8, which is equivalent.)

#### 3. 多元线性回归模型 (Multivariate Linear Regression Model)

* **模型 (Model):** 假设有 $D$ 个特征 (features).
  $$
  f(x_i) = a_0 + \sum_{j=1}^{D} a_j x_{ij} = a_0 + \mathbf{a}^T \mathbf{x}_i
  $$

  (where $\mathbf{x}_i = [x_{i1}, \dots, x_{iD}]^T$, and $\mathbf{a} = [a_1, \dots, a_D]^T$)
* **最小化均方误差 (Minimizing Mean Squared Error):**
  $$
  J_m(\mathbf{a}, a_0) = \frac{1}{m} \sum_{i=1}^{m} (y_i - f(\mathbf{x}_i))^2
  $$
* **矩阵表示 (Matrix Notation):**
  * Let $\mathbf{X}$ be an $m \times (D+1)$ matrix where each row is $[1, x_{i1}, \dots, x_{iD}]$.
  * Let $\mathbf{w} = [a_0, a_1, \dots, a_D]^T$.
  * Then $f(\mathbf{X}) = \mathbf{Xw}$.
  * Loss: $J(\mathbf{w}) = \frac{1}{m} (\mathbf{y} - \mathbf{Xw})^T (\mathbf{y} - \mathbf{Xw})$
  * **正规方程解 (Normal Equation Solution):**
    $$
    \mathbf{w} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
    $$

    (The slide uses a slightly different matrix setup where `X` is $(D+1) \times m$ and the solution derived is $\mathbf{a} = (XX^T)^{-1} Xy$. This depends on how X and y are defined. The one above is more standard if samples are rows.)
  * The slide shows $X$ with features as rows, samples as columns, and an added row of 1s for the bias term $a_0$.
    $X = \begin{pmatrix} x_{1,1} & x_{1,2} & \dots & x_{1,m} \\ \vdots & \vdots & \ddots & \vdots \\ x_{D,1} & x_{D,2} & \dots & x_{D,m} \\ 1 & 1 & \dots & 1 \end{pmatrix}$, $y = [y_1, \dots, y_m]$. Parameter vector $\mathbf{a}$ is $(D+1) \times 1$. Then $y_{pred} = \mathbf{a}^T X$.

#### 4. 从线性回归到非线性回归：逻辑斯蒂回归 (From Linear to Non-linear Regression: Logistic Regression)

* **线性回归的局限 (Limitations of Linear Regression):**
  * 对离群点 (outliers) 非常敏感。
  * 输出范围无界，不适合分类问题。
* **逻辑斯蒂回归 (Logistic Regression):**
  * 引入 Sigmoid (Logistic) 函数，将输出映射到 (0,1) 区间，解释为概率。
  * **Sigmoid 函数:**
    $$
    \sigma(z) = \frac{1}{1 + e^{-z}}
    $$
  * **模型 (Model):** $P(y=1 | \mathbf{x}) = \sigma(\mathbf{w}^T \mathbf{x} + b)$
  * **推广 (Generalization to multi-class):** Softmax 回归 (Softmax Regression) 或多项逻辑斯蒂回归 (Multinomial Logistic Regression).

---

### 三、(人工)神经网络概述 (Overview of (Artificial) Neural Networks)

#### 1. 神经网络基本单元 (Basic Unit of Neural Network)

* **MCP 神经元 (McCulloch-Pitts Neuron) (1943):**
  * **历史意义 (Historical Significance):** "我们在科学史上第一次知道了我们是怎么知道的 (for the first time in the history of science, we know how we know)"
  * **核心假设 (Core Assumptions):**
    1. **二值输出 (Binary Output):** 0 (不激活 - inactive) 或 1 (激活 - active).
    2. **线性加权和 (Linear Weighted Sum):** 输入信号乘以各自权重，求和。
    3. **阈值函数 (Threshold Function):** 若加权和超阈值，输出1，否则0。
  * **局限 (Limitations):** 无法学习权重和阈值。

#### 2. 神经元因何链接：赫布理论 (Why Neurons Connect: Hebbian Theory)

* **赫布理论 (Hebbian Theory) (Donald Hebb, 1949):**
  * "神经元之间持续重复经验刺激可导致突触传递效能增加 (Neurons that fire together, wire together)"
  * **历史意义 (Historical Significance):** 学习与记忆的生理学基础。解释大脑如何通过经验学习。
  * 为人工神经网络的权重更新和学习规则设计提供了理论基础。

#### 3. 神经元链接成“网”：感知机 (Neurons Connect into a "Network": Perceptron)

* **感知机 (Perceptron) (Frank Rosenblatt, 1950s):**
  * 仅包含输入层和输出层的两层神经网络。
  * **历史意义 (Historical Significance):** "能自学的电脑 (Electronic 'Brain' Teaches Itself)"
  * **基本概念 (Basic Concepts):**
    1. **输入和输出 (Input & Output):** 多个输入信号 $(x_1, \dots, x_n)$，每个通过权重 $(w_1, \dots, w_n)$ 加权。输出是加权和通过激活函数 (通常是阶跃函数 - step function) 的结果。
    2. **权重 (Weights):** 表示各输入信号的重要性。
    3. **激活函数 (Activation Function):** 阶跃函数，若加权和超阈值，输出1，否则0。
    4. **学习规则 (Learning Rule):** 核心特性。当感知机错判时，调整权重以减少错误。
  * **意义和局限 (Significance and Limitations):**
    * 可解决线性可分问题 (linearly separable problems)。
    * 无法处理非线性可分问题 (e.g., XOR 异或问题)。
    * 是深度学习和现代神经网络的先驱。

#### 4. 神经元之间刺激可层层递进学习：误差反向传播 (Stimuli Can Propagate Layer by Layer for Learning: Error Backpropagation)

* **误差反向传播算法 (Error Backpropagation Algorithm) (Werbos 1974, Rumelhart, Hinton et al. 1986):**
  * 解决了多层感知机 (Multi-Layer Perceptron, MLP) 中参数优化的难题。
  * **历史意义 (Historical Significance):** 以数据驱动方式根据输出误差自动优化神经网络参数成为可能。
  * **主要步骤 (Main Steps):**
    1. **前向传播 (Forward Propagation):** 输入信号逐层传递至输出层。
    2. **计算误差 (Calculate Error):** 计算输出层实际输出与期望输出之间的误差 (通过损失函数)。
    3. **反向传播误差 (Backward Propagate Error):** 将输出层误差反向传回网络，计算每层神经元的误差贡献 (使用链式法则 - chain rule)。
    4. **更新权重 (Update Weights):** 根据误差贡献调整连接权重。

#### 5. 逐层抽象、层层递进：深度学习 (Hierarchical Abstraction, Layer by Layer Progression: Deep Learning)

* **深度信念网络 (Deep Belief Network, DBN) (Hinton et al., 2006):**
  * 在 Science 等期刊发表，性能超过传统浅层学习模型 (e.g., SVM)。
  * **历史意义 (Historical Significance):** 端到端 (end-to-end) 的深度学习框架建立。
* **引发 AI 第三次崛起 (Sparked the Third AI Boom):**
  * **语言大模型 (Large Language Models, LLMs):**
    * RNN, LSTM, CNN (用于NLP), Word2vec, BERT, Transformer, LLM.
  * **历史意义:** 从造人 (simulating humans) 和造脑 (simulating brains) 到更通用的人工智能。

---

### 四、前馈神经网络 (Feedforward Neural Networks, FNNs)

#### 1. 神经元 (Neuron)

* **生物学背景 (Biological Background):** 神经元细胞有兴奋 (excitation) 与抑制 (inhibition) 两种状态。
* **MCP 模型 (MCP Model):**

  $$
  y = \Phi \left( \sum_{i=1}^n w_i x_i - \theta \right)
  $$

  或通常写作 (with bias $b = -\theta$ absorbed into sum or as a separate term):
  $$
  y = \Phi \left( \sum_{i=1}^n w_i x_i + b \right)
  $$

  * $x_i$: 二值化输入 (0 or 1)
  * $w_i$: 连接权重
  * $\Phi(\cdot)$: 激活函数 (e.g., step function)
  * $\theta$: 阈值 (threshold)

#### 2. 感知机 (Perceptron)

* **单层感知机 (Single-Layer Perceptron):** 输入层 + 输出层。
* **权重学习:** 不是预设，而是通过迭代训练得到。
* **局限 (Limitation):** 无法模拟 XOR 等非线性可分函数。

#### 3. 前馈神经网络结构 (FNN Structure)

* 由输入层 (input layer)、若干隐藏层 (hidden layers)、输出层 (output layer) 构成。
* **全连接 (Fully Connected):** 相邻层之间的神经元通常“全连接”。同一层内神经元无连接。
* **能力 (Capability):** 可以模拟复杂非线性函数。复杂性取决于隐藏层数目和神经元数目。

#### 4. FNN 核心思想 (Core Ideas of FNN)

* **层层递进、逐层抽象 (Layer-wise progression, hierarchical abstraction):** e.g., 像素 -> 边缘 -> 部件 -> 对象。
* **非线性映射 (Non-linear mapping):** 通过激活函数实现。
* **误差反馈调优 (Error feedback tuning):** 通过反向传播算法调整权重和参数。

#### 5. 执行非线性映射的激活函数 (Activation Functions for Non-linear Mapping)

* **Sigmoid 函数:**

  $$
  f(x) = \frac{1}{1 + e^{-x}}
  $$

  * **优点 (Pros):** 输出 (0,1) 可视为概率；单调递增；在0附近梯度大，易激活。
  * **缺点 (Cons):**
    * **梯度消失 (Vanishing Gradient):** $f'(x) = f(x)(1-f(x))$. 当 $f(x)$ 接近0或1时，$f'(x)$ 接近0。深层网络中梯度反向传播时，梯度会越来越小。
    * 输出不是零中心 (zero-centered)。
* **ReLU 函数 (Rectified Linear Unit):**

  $$
  f(x) = \max(0, x) = \begin{cases} x, & x \ge 0 \\ 0, & x < 0 \end{cases}
  $$

  $$
  f'(x) = \begin{cases} 1, & x > 0 \\ 0, & x < 0 \\ \text{undefined}, & x=0 \text{ (practically set to 0 or 1)} \end{cases}
  $$

  * **优点 (Pros):**
    * 缓解梯度消失问题 (for $x>0$, gradient is 1)。
    * 计算高效。
    * 稀疏性 (Sparsity): 当 $x<0$ 时，输出为0，使部分神经元失活，可能克服过拟合。
  * **缺点 (Cons):**
    * **Dying ReLU Problem:** 如果 $x<0$，梯度为0，神经元权重永不更新。
    * 输出不是零中心。
  * **变体 (Variants):** Leaky ReLU (`max(0.01x, x)`), Parametric ReLU (PReLU), ELU.
* **Softmax 函数:** 用于多分类问题的输出层。

  $$
  y_k = \text{softmax}(x_k) = \frac{e^{x_k}}{\sum_{j=1}^{C} e^{x_j}}
  $$

  (where $C$ is the number of classes)* 将任意实数值向量转换为概率分布 (各元素在(0,1)之间，和为1)。

---

### 五、神经网络参数优化 (Neural Network Parameter Optimization)

#### 1. 损失函数 (Loss Functions)

* **均方误差损失函数 (Mean Squared Error, MSE):**
  $$
  MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
  $$

  (通常用于回归问题)
* **交叉熵损失函数 (Cross-Entropy Loss):**
  $$
  H(y, \hat{y}) = - \sum_{i} y_i \log(\hat{y}_i)
  $$

  (For one-hot encoded true labels $y_i$ and predicted probabilities $\hat{y}_i$. Usually used for classification problems, often paired with Softmax output.)* “熵 (entropy)”表示系统无序程度。信息熵 (information entropy) 衡量信息不确定性。
  * 交叉熵度量两个概率分布间的差异。

#### 2. 梯度下降 (Gradient Descent)

* 使损失函数最小化的常用方法。
* **梯度 (Gradient):** 函数在某点增长最快的方向。对于一元函数 $f(x)$，梯度为 $f'(x)$。对于多元函数，梯度是偏导数向量 $\nabla f$.
  $$
  \frac{df(x)}{dx} = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
  $$
* **核心思想 (Core Idea):** 梯度的反方向是函数值下降最快的方向。
* **更新规则 (Update Rule):** $\theta_{new} = \theta_{old} - \eta \nabla_{\theta} L(\theta)$
  * $\eta$: 学习率 (learning rate)，控制步长。
  * $\nabla_{\theta} L(\theta)$: 损失函数对参数 $\theta$ 的梯度。
* **推导 (Derivation Sketch):**
  * Taylor Expansion: $f(x + \Delta x) \approx f(x) + (\nabla f(x))^T \Delta x$
  * To make $f(x + \Delta x) < f(x)$, we need $(\nabla f(x))^T \Delta x < 0$.
  * The steepest descent occurs when $\Delta x$ is in the opposite direction of $\nabla f(x)$, i.e., $\Delta x = -\eta \nabla f(x)$.
  * Then $(\nabla f(x))^T (-\eta \nabla f(x)) = -\eta ||\nabla f(x)||^2 \le 0$.
* **梯度下降的类型 (Types of Gradient Descent):**
  * **批量梯度下降 (Batch Gradient Descent, BGD):** 在整个训练集上计算损失和梯度。内存需求大，更新慢。
  * **随机梯度下降 (Stochastic Gradient Descent, SGD):** 在每个训练样本上计算损失和梯度并更新。更新快，但梯度波动大，收敛不稳定。
  * **小批量梯度下降 (Mini-batch Gradient Descent, MBGD):** 在一小批样本上计算损失和梯度。兼顾 BGD 和 SGD 的优点，是目前最常用的。

#### 3. 误差反向传播 (Error Backpropagation)

* **核心 (Core):** 利用链式法则 (chain rule) 计算损失函数对网络中各参数的偏导数。
* **过程 (Process):**
  1. **前向传播:** 计算网络输出和损失。
  2. **反向传播:**
     * 从输出层开始，计算损失对该层参数的梯度。
     * 逐层向后，利用上一层（更靠近输出层）的梯度和当前层的激活函数导数，计算当前层参数的梯度。
* **示例 (Example - Slide 47-51, 53-57):**
  * 神经单元 `out`，输入 $x$, 激活函数 $\sigma$ (sigmoid)，输出 $o = \sigma(net)$, $net = \sum w_i \cdot out_i$.
  * 目标: 调整权重 $w_1$ 以减少损失 $\mathcal{L}$.
  * 需要计算 $\frac{\partial \mathcal{L}}{\partial w_1}$.
  * 使用链式法则: $\frac{\partial \mathcal{L}}{\partial w_1} = \frac{\partial \mathcal{L}}{\partial o} \cdot \frac{\partial o}{\partial net} \cdot \frac{\partial net}{\partial w_1}$
    * $\frac{\partial \mathcal{L}}{\partial o}$: 取决于损失函数的定义 (e.g., if MSE, $(o-y_{true})$)。
    * $\frac{\partial o}{\partial net}$: Sigmoid的导数, $o(1-o)$.
    * $\frac{\partial net}{\partial w_1}$: $out_1$.
  * 更新 $w_1^{new} = w_1 - \eta \frac{\partial \mathcal{L}}{\partial w_1}$.
  * 对于更深层网络的权重，链式法则会更长，涉及更多项的乘积。

---

### (回顾与综合) 深度学习核心组件 (Core Components of Deep Learning - Review and Synthesis)

#### 1. 深度学习公式 (Deep Learning Formula)

* **深度学习 (Deep Learning) = 人工神经网络 (Artificial Neural Network) + 训练学习策略 (Training Strategy)**
* Example: $y = f(\mathbf{x}; \theta)$ where $\theta$ are learnable parameters.

#### 2. 多层感知机 (Multi-Layer Perceptron, MLP)

* `self.MLP = nn.Sequential(nn.Linear(C, C'), nn.ReLU(), ...)`
* 激活函数: Sigmoid, Tanh, ReLU, LeakyReLU.

#### 3. 卷积神经网络 (Convolutional Neural Networks, CNNs)

* **为什么是卷积 (Why Convolution?):**
  * FNNs 对图像数据参数过多 (e.g., $1000 \times 1000$ image -> $10^{12}$ parameters if fully connected to first hidden layer of same size).
  * CNNs 利用图像的**局部相关性 (local correlation)** 和**参数共享 (parameter sharing)**。
* **核心操作 (Core Operations):**
  * **卷积层 (Convolutional Layer):**
    $$
    I'(x,y) = \sum_{i=-\lfloor h/2 \rfloor}^{\lfloor h/2 \rfloor} \sum_{j=-\lfloor w/2 \rfloor}^{\lfloor w/2 \rfloor} W(i,j) \cdot I(x+i, y+j) + b(i,j)
    $$

    * $W$: 卷积核 (kernel) / 滤波器 (filter) - 可学习的参数。
    * $I$: 输入特征图 (input feature map)。
    * $I'$: 输出特征图 (output feature map)。
    * $b$: 偏置项 (bias) - 可学习。
    * **感受野 (Receptive Field):** 卷积核覆盖的输入区域。
    * **局部感知 (Local Perception):** 神经元只对局部区域响应。
    * **参数共享 (Parameter Sharing):** 同一个卷积核在整个输入图上滑动，参数被重用。
  * **填充 (Padding):** 在输入图像边缘补0，以控制输出特征图大小，并使边缘像素得到充分利用。
  * **步长 (Stride):** 卷积核滑动的步幅。Stride > 1 可以实现下采样 (downsampling)。
  * **空洞卷积 / 扩张卷积 (Dilated Convolution / Atrous Convolution):** 在卷积核元素之间插入空洞，增大感受野而不增加参数。
  * **池化层 (Pooling Layer):**
    * **最大池化 (Max Pooling):** 取区域内的最大值。提供少量平移不变性。
    * **平均池化 (Average Pooling):** 取区域内的平均值。
    * 作用: 降维，减少计算量，增大感受野，引入一定不变性。
* **典型 CNN 架构 (Typical CNN Architecture):**
  * (Input -> [Conv -> ReLU -> Pool]*N -> [FC -> ReLU]*M -> Softmax)
  * **AlexNet (2012):** 包含卷积层、池化层、ReLU、全连接层、Dropout。

#### 4. 循环神经网络 (Recurrent Neural Networks, RNNs)

* **处理序列数据 (Processing Sequential Data):** 文本、语音、时间序列。
* **循环结构 (Recurrent Structure):**

  $$
  \mathbf{h}_t = \phi(\mathbf{W}_{xh} \mathbf{x}_t + \mathbf{W}_{hh} \mathbf{h}_{t-1} + \mathbf{b}_h)
  $$

  $$
  \mathbf{o}_t = \psi(\mathbf{W}_{ho} \mathbf{h}_t + \mathbf{b}_o)
  $$

  * $\mathbf{h}_t$: 时刻 $t$ 的隐藏状态 (hidden state)，携带历史信息。
  * $\mathbf{x}_t$: 时刻 $t$ 的输入。
  * $\phi, \psi$: 激活函数 (e.g., tanh, sigmoid, softmax)。
  * $\mathbf{W}, \mathbf{b}$: 可学习的权重和偏置，在所有时间步共享。
* **梯度消失/爆炸问题 (Vanishing/Exploding Gradient Problem):**

  * 在通过时间反向传播 (Backpropagation Through Time, BPTT) 时，梯度连乘导致梯度过小或过大，难以学习长期依赖 (long-term dependencies)。
  * $\frac{\partial \mathcal{L}_t}{\partial W_x} = \sum_{k=1}^{t} \frac{\partial \mathcal{L}_t}{\partial o_t} \frac{\partial o_t}{\partial h_t} (\prod_{j=k+1}^{t} \frac{\partial h_j}{\partial h_{j-1}}) \frac{\partial h_k}{\partial W_x}$
  * The term $\prod \frac{\partial h_j}{\partial h_{j-1}}$ involves repeated multiplication of $W_{hh}$, leading to issues.
* **长短时记忆网络 (Long Short-Term Memory, LSTM) (Hochreiter & Schmidhuber, 1997):**

  * 引入门控机制 (gating mechanism) 和细胞状态 (cell state) 来控制信息流动。
  * **门 (Gates):**

    * 遗忘门 (Forget Gate, $f_t$): 决定从细胞状态中丢弃什么信息。
    * 输入门 (Input Gate, $i_t$): 决定什么新信息存入细胞状态。
    * 输出门 (Output Gate, $o_t$): 决定细胞状态的哪部分输出。
  * **细胞状态 (Cell State, $C_t$):** 线性流动，信息易于保持。

    $$
    f_t = \sigma(W_f x_t + U_f h_{t-1} + b_f)
    $$

    $$
    i_t = \sigma(W_i x_t + U_i h_{t-1} + b_i)
    $$

    $$
    \tilde{C}_t = \tanh(W_C x_t + U_C h_{t-1} + b_C)
    $$

    $$
    C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t
    $$

    $$
    o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o)
    $$

    $$
    h_t = o_t \odot \tanh(C_t)
    $$

    ($\odot$ is element-wise product)
* **门控循环单元 (Gated Recurrent Unit, GRU) (Cho et al., 2014):**

  * 简化的 LSTM，只有更新门 (update gate, $z_t$) 和重置门 (reset gate, $r_t$)。
* **应用模式 (Application Patterns):**

  * 多对一 (Many-to-one): 情感分析, 文本分类。
  * 一对多 (One-to-many): 图像描述生成, 音乐生成。
  * 多对多 (Many-to-many): 机器翻译, 视频帧标注。
* **双向 RNN (Bidirectional RNN, BiRNN):** 同时考虑过去和未来的上下文信息。

#### 5. 注意力机制与 Transformer (Attention Mechanism and Transformer)

* **注意力机制 (Attention Mechanism):**
  * 允许模型在处理序列时，动态地关注输入序列的不同部分。
  * **核心思想:** 计算查询 (Query, Q) 与一组键 (Keys, K) 之间的相似度，用相似度作为权重对对应的值 (Values, V) 进行加权求和。
  * **自注意力 (Self-Attention):** Q, K, V 来自同一输入序列。
    $$
    \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
    $$

    * $\sqrt{d_k}$: 缩放因子，防止点积过大。
* **Transformer (Vaswani et al., 2017 "Attention Is All You Need"):**
  * 完全基于自注意力机制，不使用 RNN 或 CNN (在编码器-解码器中)。
  * **主要组件 (Main Components):**
    * **多头注意力 (Multi-Head Attention):** 并行运行多个注意力“头”，每个头学习不同的注意力表示，然后拼接并线性变换。
    * **位置编码 (Positional Encoding):** 因为自注意力本身不处理序列顺序，需加入位置信息。
    * **前馈网络 (Feed-Forward Networks):** 在每个注意力子层后。
    * **残差连接 (Residual Connections) 和层归一化 (Layer Normalization):** 帮助训练深层网络。
  * **卷积 vs. Transformer:**
    * 卷积: 固定的局部感受野，通过堆叠层数扩大感受野。权重固定，与内容无关（但权重本身是学到的）。编码相对位置信息。
    * Transformer (Self-Attention): 动态的全局感受野，一次看到所有token。权重（注意力得分）是动态计算的，与内容相关。需要显式位置编码。

#### 6. 图神经网络 (Graph Neural Networks, GNNs)

* 处理图结构数据。
* **核心思想：消息传递 (Message Passing)**

  1. **节点表示 (Node Representation):** 每个节点有特征向量。
  2. **边表示 (Edge Representation):** 边也可以有特征。
  3. **聚合函数 (Aggregation Function):** 节点聚合其邻居节点的信息 (e.g., sum, mean, max)。
  4. **更新函数 (Update Function):** 节点结合聚合到的信息和自身前一状态来更新其表示。

  * Example: $h_v^{(k)} = \text{UPDATE}^{(k)}(h_v^{(k-1)}, \text{AGGREGATE}^{(k)}(\{h_u^{(k-1)} : u \in \mathcal{N}(v)\}))$

---

### 六、神经网络正则化 (Neural Network Regularization)

* **目的 (Purpose):** 缓解过拟合 (overfitting)，提升泛化能力 (generalization)。
* **过拟合原因 (Causes of Overfitting):** 模型参数量过多、数据量不足。

#### 1. Dropout

* **思想 (Idea):** 在训练过程中，以一定概率随机“丢弃”（即暂时移除）一部分神经元及其连接。
* **效果 (Effect):**
  * 每次迭代训练的是一个“变瘦”的子网络。
  * 类似训练多个不同网络并进行模型平均 (model averaging) 的效果。
  * 迫使网络学习更鲁棒的特征，不过分依赖某些特定神经元。

#### 2. 批归一化 (Batch Normalization, BN)

* **思想 (Idea):** 对每一批 (mini-batch) 数据，在网络每一层的激活函数输入之前，进行归一化处理，使其均值为0，方差为1。然后再进行缩放 (scale) 和平移 (shift)。

  $$
  \mu_B = \frac{1}{m} \sum_{i=1}^m x_i
  $$

  $$
  \sigma_B^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_B)^2
  $$

  $$
  \hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
  $$

  $$
  y_i = \gamma \hat{x}_i + \beta
  $$

  * $\gamma, \beta$: 可学习的缩放和平移参数。
  * $\epsilon$: 防止除零的小常数。
* **效果 (Effect):**

  * 缓解内部协变量偏移 (Internal Covariate Shift)，使每层输入分布更稳定。
  * 加快收敛速度。
  * 允许使用更高的学习率。
  * 具有一定的正则化效果 (因mini-batch的均值和方差带有噪声)。
  * 将输入值映射到激活函数梯度较大的区域，缓解梯度消失。

#### 3. L1 和 L2 正则化 (L1 and L2 Regularization)

* 在损失函数中加入对权重的惩罚项。
* **L2 正则化 (Weight Decay / Ridge):**
  $$
  L_{total} = L_{original} + \frac{\lambda}{2N} \sum_w w^2
  $$

  * 惩罚大的权重，使权重分布更平滑，防止模型过于依赖少数特征。
* **L1 正则化 (Lasso):**
  $$
  L_{total} = L_{original} + \frac{\lambda}{N} \sum_w |w|
  $$

  * 倾向于产生稀疏权重 (sparse weights)，即许多权重为0。可用于特征选择。
* **L0 正则化:** 惩罚非零权重的个数 (NP-hard, 实践中少用)。

---

### 七、易错点与Q&A (Common Mistakes and Q&A)

* **Q1: 验证集和测试集有什么区别？(What's the difference between validation set and test set?)**
  * **A:** 验证集用于模型选择和超参数调整（如学习率、网络层数）。测试集仅用于对最终选定的模型进行一次性的性能评估，其结果用于报告模型的泛化能力。测试集不应参与任何训练或调优过程。
* **Q2: 什么是过拟合？如何检测和缓解？(What is overfitting? How to detect and mitigate it?)**
  * **A:** 过拟合指模型在训练集上表现很好，但在未见过的测试集上表现差。
    * **检测 (Detection):** 训练损失持续下降，但验证损失开始上升或停滞不前。
    * **缓解 (Mitigation):**
      1. 获取更多数据 (Get more data)。
      2. 数据增强 (Data augmentation)。
      3. 简化模型 (Simplify the model: e.g., fewer layers/neurons)。
      4. 正则化 (Regularization: L1, L2, Dropout)。
      5. 早停 (Early stopping): 当验证损失不再改善时停止训练。
      6. 批归一化 (Batch Normalization)。
* **Q3: 梯度消失和梯度爆炸是什么？主要发生在哪些网络中？如何解决？(What are vanishing and exploding gradients? In which networks do they primarily occur? How to solve them?)**
  * **A:**
    * **梯度消失 (Vanishing Gradient):** 在深层网络中，梯度在反向传播时逐层递减，导致靠近输入层的权重更新缓慢或停滞。
    * **梯度爆炸 (Exploding Gradient):** 梯度逐层递增，导致权重更新过大，训练不稳定。
    * **主要发生 (Primarily occurs in):** 深层前馈网络 (尤其使用 Sigmoid/Tanh) 和循环神经网络 (RNNs) 处理长序列时。
    * **解决方法 (Solutions):**
      1. ReLU及其变体激活函数 (ReLU and its variants)。
      2. LSTM/GRU 单元 (for RNNs)。
      3. 梯度裁剪 (Gradient clipping: for exploding gradients, set a threshold for gradient values)。
      4. 权重初始化 (Proper weight initialization: e.g., Xavier, He)。
      5. 残差连接 (Residual connections: e.g., ResNet)。
      6. 批归一化 (Batch Normalization)。
* **Q4: L1 和 L2 正则化的主要区别和应用场景是什么？(What are the main differences and use cases for L1 and L2 regularization?)**
  * **A:**
    * **L1 (Lasso):** 惩罚权重的绝对值之和 ($\lambda \sum |w|$). 倾向于产生稀疏解 (使一些权重变为0)，因此可用于特征选择。其解不是唯一的。
    * **L2 (Ridge / Weight Decay):** 惩罚权重的平方和 ($\lambda \sum w^2$). 倾向于使权重值变小且分散，防止个别权重过大。其解是唯一的。
    * L2 通常比 L1 有更好的预测性能（除非特征高度稀疏且相关性低）。
* **Q5: CNN中的卷积操作和Transformer中的自注意力机制有何异同？(What are the similarities and differences between convolution in CNNs and self-attention in Transformers?)**
  * **A:**
    * **相似点 (Similarities):** 都是为了从输入中提取特征，并学习数据点之间的依赖关系。都可以看作是一种加权求和操作。
    * **不同点 (Differences):**
      1. **感受野 (Receptive Field):** 卷积具有固定的、局部的感受野。自注意力具有动态的、全局的感受野（可以看到整个输入序列）。
      2. **权重计算 (Weight Computation):** 卷积核的权重是学习到的固定参数，与输入内容无关（但作用于不同位置）。自注意力的权重（注意力得分）是根据输入内容动态计算的，表示不同部分之间的相关性。
      3. **序列顺序 (Sequence Order):** 卷积天生处理局部顺序。自注意力本身不感知顺序，需要额外的位置编码。
      4. **计算复杂度 (Computational Complexity):** 对于序列长度 $N$ 和特征维度 $D$，卷积（核大小 $K$）通常是 $O(N \cdot K \cdot D^2)$ 或 $O(N \cdot K^2 \cdot D)$。自注意力是 $O(N^2 \cdot D)$，对长序列计算成本高。

---

### 八、考试例题与示范 (Example Exam Questions and Demonstrations)

1. **简答题 (Short Answer):**

   * **题目:** 请解释监督学习、无监督学习和半监督学习的主要区别。
     * **答案示范:**
       * 监督学习 (Supervised Learning) 使用带有明确标签 (ground truth) 的数据进行训练，目标是学习一个从输入到输出的映射函数，如分类或回归。
       * 无监督学习 (Unsupervised Learning) 使用没有标签的数据进行训练，目标是发现数据本身的内在结构或模式，如聚类或降维。
       * 半监督学习 (Semi-supervised Learning) 介于两者之间，使用少量有标签数据和大量无标签数据进行训练，试图结合两者的优势。
2. **计算题/分析题 (Calculation/Analysis):**

   * **题目:** 一个二分类模型在测试集上的表现如下：TP=80, FP=20, TN=180, FN=20。请计算该模型的准确率 (Accuracy)、精确率 (Precision)、召回率 (Recall) 和 F1-score。
     * **答案示范:**
       * 总样本数 = TP+FP+TN+FN = 80+20+180+20 = 300
       * 准确率 (Accuracy) = (TP+TN) / 总 = (80+180) / 300 = 260 / 300 $\approx$ 0.867
       * 精确率 (Precision) = TP / (TP+FP) = 80 / (80+20) = 80 / 100 = 0.8
       * 召回率 (Recall) = TP / (TP+FN) = 80 / (80+20) = 80 / 100 = 0.8
       * F1-score = (2 * Precision * Recall) / (Precision + Recall) = (2 * 0.8 * 0.8) / (0.8 + 0.8) = 1.28 / 1.6 = 0.8
3. **论述题 (Discussion):**

   * **题目:** 什么是梯度消失问题？它为什么会影响深层神经网络的训练？请至少列举两种缓解该问题的方法并简要说明其原理。
     * **答案示范:**
       * 梯度消失问题是指在深层神经网络中，当使用反向传播算法计算梯度时，从输出层到输入层的过程中，梯度值会逐渐减小，甚至趋近于零。
       * 影响：靠近输入层的网络层梯度过小，导致这些层的权重参数更新非常缓慢或几乎不更新，使得这些层无法有效学习特征，整个网络的训练效果不佳。这通常发生在激活函数（如Sigmoid或Tanh）的导数在大部分区域小于1，并且梯度通过链式法则连乘时。
       * 缓解方法：
         1. **使用ReLU及其变体激活函数:** ReLU (Rectified Linear Unit) 在输入大于0时梯度恒为1，避免了梯度因激活函数导数小于1而衰减。变体如Leaky ReLU在输入小于0时也允许一个小的非零梯度，防止神经元“死亡”。
         2. **使用LSTM或GRU单元 (主要针对RNN):** LSTM (Long Short-Term Memory) 和 GRU (Gated Recurrent Unit) 内部设计了门控机制和细胞状态（LSTM），通过加法操作传递信息（LSTM的细胞状态），使得梯度能够更好地在时间步之间流动，有效缓解了长序列依赖中的梯度消失问题。
4. **选择题/填空题 (Multiple Choice/Fill-in-the-blanks):**

   * **题目:** 在机器学习中，用于防止过拟合，通过向损失函数添加模型参数的范数惩罚项的技术称为 ______ 。 (A) Dropout (B) 正则化 (Regularization) (C) 批归一化 (Batch Normalization) (D) 早停 (Early Stopping)
     * **答案:** (B) 正则化 (Regularization)
   * **题目:** Softmax激活函数通常用于神经网络的 ______ 层，以输出多分类问题的概率分布。
     * **答案:** 输出 (output)

# 机器学习与深度学习核心知识点 (Core Concepts in Machine Learning & Deep Learning)

本指南根据提供的《人工智能前沿_机器学习与深度学习》文档，系统性地整理了核心知识点、公式、易错概念及考试范例，旨在帮助您高效复习和备考。

---

### 一、 机器学习基础 (Fundamentals of Machine Learning)

#### 1.1 机器学习分类 (Types of Machine Learning)
[cite_start]机器学习通过优化算法从数据中学习，以建立能够刻画数据内在规律或语义信息的模型 。根据数据标签的使用情况，主要分为：
* [cite_start]**监督学习 (Supervised Learning):** 从完全标记好的数据 $\{(x_{i},y_{i})\}_{i=1}^{n}$ 中学习一个输入到输出的映射函数 $f$ 。
* [cite_start]**无监督学习 (Unsupervised Learning):** 从无标签的数据 $\{x_i\}$ 中学习，旨在发现数据中隐藏的结构或模式 。
* [cite_start]**半监督学习 (Semi-supervised Learning):** 使用部分有标签、部分无标签的数据进行学习 。

#### 1.2 监督学习工作流 (Supervised Learning Workflow)

1.  **数据集划分 (Data Splitting)**
    * [cite_start]**训练集 (Training Set):** 用于训练模型和优化其参数 [cite: 5][cite_start]。好比学生的“练习册” 。
    * [cite_start]**验证集 (Validation Set):** 用于在训练过程中评估模型，以调整超参数（如学习率、网络层数等），挑选出最佳模型 [cite: 5][cite_start]。好比学生的“模拟考” 。
    * [cite_start]**测试集 (Test Set):** 在模型训练和调优全部完成后，用于最终评估模型性能的独立数据集 [cite: 5][cite_start]。好比真正的“大考” 。

    !!! important "重要 (Important)"
        [cite_start]这三个数据集必须严格独立，没有任何数据交叉，以保证模型评估的客观性和公正性 。

2.  **风险与泛化 (Risk and Generalization)**
    * [cite_start]**损失函数 (Loss Function):** 一个用于衡量模型预测值 $\hat{y} = f(x_i)$ 与真实值 $y_i$ 之间差异的函数，记为 $Loss(f(x_i), y_i)$ 。
        * [cite_start]**平方损失 (Square Loss):** $$Loss(y_{i},f(x_{i}))=(y_{i}-f(x_{i}))^{2} \text{}$$
        * [cite_start]**0-1损失 (0-1 Loss):** $$Loss(y_{i},f(x_{i}))=\begin{cases}1, & f(x_{i})\ne y_{i}\\ 0, & f(x_{i})=y_{i}\end{cases} \text{}$$
        * [cite_start]**交叉熵损失 (Cross-Entropy Loss) / 对数似然损失 (Log-Likelihood Loss):** $$Loss(y_{i},P(y_{i}|x_{i}))=-\log P(y_{i}|x_{i}) \text{}$$
    * [cite_start]**经验风险 (Empirical Risk) $\mathfrak{R}_{emp}$:** 模型在 **训练数据** 上的平均损失 。
        [cite_start]$$\mathfrak{R}_{emp} = \frac{1}{n}\sum_{l=1}^{n}Loss(y_{l},f(x_{l})) \text{}$$
    * [cite_start]**期望风险 (Expected Risk) $\mathfrak{R}$:** 模型在 **所有可能数据** 上的期望损失，是模型性能的真实度量，但通常无法直接计算 。
        [cite_start]$$\mathfrak{R} = \int_{x \times y}Loss(y,f(x))P(x,y)dxdy \text{}$$
    * [cite_start]**泛化能力 (Generalization):** 指模型在训练集和测试集上性能表现一致的能力 [cite: 13][cite_start]。一个泛化能力强的模型，其期望风险较低 。

3.  **过拟合与欠拟合 (Overfitting & Underfitting)**
    * [cite_start]**欠学习 (Underfitting):** 模型过于简单，在训练集和测试集上都表现不佳（经验风险和期望风险都很高）。
    * [cite_start]**过学习 (Overfitting):** 模型过于复杂，对训练数据拟合得很好，但在新数据上表现差（经验风险低，但期望风险高）。

4.  **正则化 (Regularization)**
    [cite_start]为防止过拟合，在损失函数中加入惩罚模型复杂度的项。这种策略被称为 **结构风险最小化 (Structural Risk Minimization, SRM)** 。
    [cite_start]$$\min \left( \frac{1}{n}\sum_{i=1}^{n}Loss(y_{i},f(x_{i}))+\lambda J(f) \right) \text{}$$
    * [cite_start]$J(f)$ 是 **正则化项 (regularizer)**，用于度量模型复杂度 。
    * $\lambda$ 是 **正则化权重 (regularization coefficient)**，用于平衡经验风险和模型复杂度 。

#### 1.3 模型评估指标 (Model Evaluation Metrics)
对于二分类问题 (Binary Classification) ：
* [cite_start]**准确率 (Accuracy):** $$ACC=\frac{TP+TN}{P+N} \text{}$$
* [cite_start]**精确率 (Precision) / 查准率:** $$precision=\frac{TP}{TP+FP} \text{}$$
* **召回率 (Recall) / 查全率:** $$recall=\frac{TP}{TP+FN} \text{}$$
* [cite_start]**F1-Score:** 精确率和召回率的调和平均数，用于综合评估 。
    [cite_start]$$F1-score = \frac{2 \times Precision \times Recall}{Precision + Recall} \text{}$$

---

### 二、 经典机器学习模型 (Classic Machine Learning Models)

#### 2.1 线性回归 (Linear Regression)
[cite_start]分析变量间的线性关系 。
* [cite_start]**一元线性回归 (Univariate Linear Regression):** 寻找最佳直线 $y = ax + b$ 拟合数据 [cite: 26][cite_start]。参数通过 **最小二乘法 (Least Squares Method)** 求解，即最小化残差平方和 $L(a,b)=\sum_{i=1}^{n}(y_{i}-ax_{i}-b)^{2}$ 。
    * 参数解为：
        $$b=\overline{y}-a\overline{x} \text{}$$
        $$a=\frac{\sum x_i y_i - n\overline{x}\overline{y}}{\sum x_i^2 - n\overline{x}^2} \text{}$$
* [cite_start]**多元线性回归 (Multivariate Linear Regression):** 扩展到多维特征 $x_i \in \mathbb{R}^D$ [cite: 35][cite_start]。模型为 $f(x_{i})=a_{0}+a^{T}x_{i}$ [cite: 35][cite_start]。其矩阵形式的解为 ：
    $$a=(XX^{T})^{-1}Xy$$

#### 2.2 逻辑斯蒂回归 (Logistic Regression)
[cite_start]一种用于分类任务的非线性回归模型，尤其适用于二分类 [cite: 40, 41][cite_start]。它通过 **Sigmoid** 函数将线性回归的输出映射到 (0, 1) 区间，解释为概率 。
[cite_start]$$y=\frac{1}{1+e^{-z}}=\frac{1}{1+e^{-(w^{T}x+b)}} \text{}$$
[cite_start]其多分类推广是 **Softmax 回归** 。

---

### 三、 神经网络与深度学习 (Neural Networks & Deep Learning)

#### 3.1 神经网络基本单元 (The Basic Unit: The Neuron)
* [cite_start]**MCP 模型 (MCP Model, 1943):** 首个神经元数学模型，通过对输入进行线性加权求和，然后与一个阈值比较来产生二值输出 [cite: 42, 48][cite_start]。它本身无法学习 。
* [cite_start]**感知机 (Perceptron, 1950s):** 一个包含输入层和输出层的两层神经网络，引入了学习规则，能够自动调整权重来解决 **线性可分** 问题 [cite: 44, 45][cite_start]。但它无法解决非线性可分问题，如 **异或 (XOR)** 。

#### 3.2 前馈神经网络 (Feedforward Neural Networks, FNN/MLP)
[cite_start]也称 **多层感知机 (Multi-Layer Perceptron)**，在感知机基础上增加了若干 **隐藏层 (hidden layers)**，极大地增强了模型的非线性表达能力 。
* [cite_start]**全连接 (Fully Connected):** 相邻两层的神经元通常是全连接的，但同层内的神经元不连接 。
* **激活函数 (Activation Functions):** 引入非线性是其核心。
    * [cite_start]**Sigmoid/Tanh:** S型函数，存在 **梯度消失 (vanishing gradient)** 的问题 。
    * [cite_start]**ReLU (Rectified Linear Unit):** $f(x)=max(0,x)$。是现代深度学习中最常用的激活函数，有效缓解了梯度消失问题，但可能导致“神经元死亡 (Dying ReLU)” 。
    * **Softmax:** 通常用于多分类任务的输出层，将输出转换为概率分布 。

#### 3.3 训练神经网络 (Training Neural Networks)
1.  **损失函数 (Loss Function):** 
    * [cite_start]**均方误差 (MSE):** 主要用于回归任务 [cite: 68][cite_start]。$$MSE=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2} \text{}$$
    * [cite_start]**交叉熵损失 (Cross-Entropy Loss):** 主要用于分类任务，衡量两个概率分布的差异 [cite: 69][cite_start]。$$H(y_{i},\hat{y}_{i})=-y_{i} \cdot \log\hat{y}_{i} \text{}$$
2.  [cite_start]**梯度下降 (Gradient Descent):** 优化模型参数的常用方法，通过沿梯度的反方向更新参数来使损失函数最小化 。
    $$\theta_{new} = \theta_{old} - \eta\nabla L(\theta)$$
    * $\eta$ 是 **学习率 (learning rate)** 。
    * [cite_start]**类型:** 批量(Batch)、随机(Stochastic, SGD)、小批量(Mini-batch) [cite: 85][cite_start]。小批量是目前最常用的方法 。
3.  [cite_start]**反向传播算法 (Backpropagation):** 高效计算网络中所有参数梯度的算法 [cite: 46, 77][cite_start]。它从输出层开始，利用 **链式求导法则 (chain rule)**，逐层向后计算梯度，并更新参数 。

#### 3.4 卷积神经网络 (Convolutional Neural Networks, CNN)
[cite_start]为处理图像等网格状数据而设计的神经网络 。
* **核心思想 (Core Ideas):**
    * [cite_start]**局部感知 (Local Receptive Fields):** 每个神经元只与输入的一个局部区域（感受野）相连 。
    * **参数共享 (Parameter Sharing):** 一个 **卷积核 (kernel/filter)** 在整个输入图像上滑动，共享同一组权重，极大减少了模型参数量 。
* **关键操作 (Key Operations):**
    * **卷积 (Convolution):** 卷积核与输入图像的局部区域进行加权求和，生成 **特征图 (feature map)** 。
    * [cite_start]**池化 (Pooling):** 对特征图进行下采样，降低维度，并提供一定的平移不变性 [cite: 107, 128][cite_start]。最常见的有 **最大池化 (Max Pooling)** 和 **平均池化 (Average Pooling)** 。
    * **填充 (Padding):** 在图像边缘填充0，以处理边缘像素并控制输出尺寸 。
    * [cite_start]**步长 (Stride):** 卷积核每次滑动的距离，大于1的步长可以实现下采样 。

#### 3.5 循环神经网络 (Recurrent Neural Networks, RNN)
[cite_start]为处理文本、时间序列等 **序列数据 (sequential data)** 而设计 。
* **核心思想 (Core Idea):** RNN 维护一个 **隐藏状态 (hidden state, $h_t$)**，该状态包含了过去序列的信息，并与当前输入 $x_t$ 一同决定当前输出。这个循环结构使其具有“记忆”能力 。
    [cite_start]$$h_{t}=\Phi(U \cdot x_{t}+W \cdot h_{t-1}) \text{}$$
* [cite_start]**长期依赖问题 (Long-Term Dependency Problem):** 标准RNN在处理长序列时，由于反向传播路径过长，容易出现 **梯度消失/爆炸 (vanishing/exploding gradient)** 问题，难以学习到长距离的依赖关系 。

#### 3.6 LSTM 和 GRU
为解决RNN的长期依赖问题而提出的高级RNN变体。
* [cite_start]**长短时记忆网络 (Long Short-Term Memory, LSTM):** 引入了 **细胞状态 (cell state)** 作为信息传送带，并通过三个精巧的 **门 (gates)**——**遗忘门 (forget gate)**、**输入门 (input gate)** 和 **输出门 (output gate)**——来控制信息的流入、流出和遗忘 [cite: 143, 144][cite_start]。这种加性更新机制有效缓解了梯度消失 。
* [cite_start]**门控循环单元 (Gated Recurrent Unit, GRU):** 是LSTM的一个简化版本，将遗忘门和输入门合并为 **更新门 (update gate)**，并引入 **重置门 (reset gate)**，参数更少，性能与LSTM相当 。

#### 3.7 注意力机制与 Transformer (Attention and Transformer)
* [cite_start]**注意力机制 (Attention Mechanism):** 允许模型在生成输出时，动态地将“注意力”集中在输入序列中最相关的部分 。
* **Transformer (2017):** 一个完全基于注意力机制，摒弃了循环和卷积的革命性架构 。
    * [cite_start]**自注意力 (Self-Attention):** Transformer的核心，它直接计算序列中所有单词对之间的关联度，并据此更新每个单词的表示 。
    * [cite_start]**Q, K, V (Query, Key, Value):** 自注意力通过将输入映射到这三个向量来计算注意力权重 [cite: 170][cite_start]。$Q$ 代表当前单词的查询， $K$ 代表其他单词的“键”，$V$ 代表其他单词的“值” 。
    * [cite_start]**优势 (Advantages):** 能够并行处理整个序列，训练速度远超RNN [cite: 171][cite_start]；通过直接连接任意两个位置，能更有效地捕捉长距离依赖 。

---

### 易错点与Q&A (Common Pitfalls & Q&A)

> **❓ Q1: 验证集 (validation set) 和测试集 (test set) 到底有什么区别？它们不都是用来测试模型吗？**
    **A1:** 这是一个非常关键且常见的混淆点。
    * [cite_start]**验证集** 是 **训练过程的一部分**。你在训练 *期间* 使用它来监控模型表现，并据此调整超参数（如学习率、网络结构、正则化强度等）。你可以多次在验证集上进行测试。把它想象成指导你学习的 **“模拟考试 (mock exam)”** 。
    * **测试集** 在所有训练和调优完成后 **只使用一次**。它的唯一目的是对最终模型的泛化能力给出一个无偏的、最终的评估。如果你用它来调参，就相当于“作弊”，因为模型会开始对测试集过拟合，导致你对模型性能的评估过于乐观。把它想象成 **“最终大考 (final exam)”** 。

> **❓ Q2: 我的模型在训练集上有99%的准确率，但在测试集上只有60%，这是怎么回事？**
    **A2:** 这是典型的 **过拟合 (overfitting)** 现象 。你的模型过度学习了训练数据的细节和噪声，而没有学到普适的规律。
    * **如何解决？**
        1.  **获取更多数据:** 增加训练数据量是最好的方法。
        2.  [cite_start]**使用正则化 (Regularization):** 在损失函数中加入L1或L2惩罚项 。
        3.  [cite_start]**使用 Dropout:** 在训练中随机“丢弃”一些神经元，强制网络学习更鲁棒的特征 。
        4.  [cite_start]**使用批归一化 (Batch Normalization):** 规范化每层输入，有助于稳定训练并有轻微的正则化效果 。
        5.  **简化模型:** 使用更少的层或神经元。

> **❓ Q3: 为什么ReLU这么流行？为什么不用Sigmoid？**
    [cite_start]**A3:** 对于隐藏层，ReLU ($f(x)=max(0,x)$)  相较于Sigmoid有几个关键优势：
    1.  [cite_start]**缓解梯度消失:** 对于正输入，ReLU的导数恒为1 [cite: 65][cite_start]。而Sigmoid的导数最大只有0.25 [cite: 64][cite_start]。在深层网络中，多个小于1的梯度连乘会导致梯度信号消失，使浅层网络无法学习 。
    2.  **计算效率高:** ReLU只是一个简单的比较操作，比Sigmoid中的指数运算快得多。
    3.  [cite_start]**稀疏性:** ReLU会将负输入置为0，产生稀疏的激活，这在计算上和表示上都可能更高效 。

> **❓ Q4: LSTM相对于标准RNN的核心创新是什么？**
    [cite_start]**A4:** 核心创新在于引入了 **细胞状态 (cell state)** [cite: 143][cite_start]。标准RNN将新输入和旧状态通过一次复杂的非线性变换融合，梯度难以传递 [cite: 141][cite_start]。而LSTM的细胞状态是一条独立的“信息高速公路”，主要通过 **加法** 进行更新 ($c_t = f_t \odot c_{t-1} + \dots$) [cite: 144][cite_start]。在求导时，$\frac{\partial c_t}{\partial c_{t-1}}$ 直接包含了遗忘门 $f_t$ [cite: 146][cite_start]。网络可以学会将 $f_t$ 设置为接近1，从而让梯度几乎无衰减地流过，有效解决了梯度消失问题 。

---

### 考试例题与示范 (Example Exam Questions & Solutions)

> **📝 例题1: 概念辨析 (Conceptual Question)**
    **问题:** 简要解释什么是经验风险最小化（ERM），并说明为什么在实践中仅使用ERM可能会导致问题。我们通常如何改进它？
    
    **示范答案 (Model Answer):**

    [cite_start]**经验风险最小化 (Empirical Risk Minimization, ERM)** 是一种机器学习优化策略，其目标是寻找一个模型参数，使得该模型在 **训练集** 上的平均损失（即经验风险 $\mathfrak{R}_{emp}$）最小化 [cite: 15][cite_start]。经验风险的数学定义为：$\mathfrak{R}_{emp} = \frac{1}{n}\sum_{l=1}^{n}Loss(y_{l},f(x_{l}))$ 。

    [cite_start]**仅使用ERM的问题** 在于，它可能会导致 **过拟合 (Overfitting)** [cite: 8][cite_start]。当一个复杂模型在训练数据上被过度优化时，它会学习到训练数据特有的噪声和偶然模式，而不是数据背后通用的规律。这会导致模型在训练集上表现很好（经验风险低），但在未见过的测试集上表现很差（期望风险高），即泛化能力差 。

    [cite_start]**为了改进ERM**，我们引入了 **结构风险最小化 (Structural Risk Minimization, SRM)** 的思想 [cite: 9][cite_start]。SRM在经验风险的基础上，增加了一个用于惩罚模型复杂度的 **正则化项 (Regularization Term)** [cite: 9][cite_start]。优化目标变为在经验风险和模型复杂度之间寻找平衡 ：
    [cite_start]$$\min \left( \frac{1}{n}\sum_{i=1}^{n}Loss(y_{i},f(x_{i}))+\lambda J(f) \right) \text{}$$
    通过这种方式，我们可以防止模型变得过于复杂，从而提升其泛化能力。

> **📝 例题2: 模型分析 (Model Analysis)**
    **问题:** 卷积神经网络（CNN）中的“参数共享”是什么意思？它带来了什么关键优势？

    **示范答案 (Model Answer):**

    [cite_start]在卷积神经网络（CNN）中，**参数共享 (Parameter Sharing)** 是指在对输入数据（如图像）进行卷积操作时，使用 **同一个卷积核 (kernel/filter)** 在输入数据的所有空间位置上进行计算 。这个卷积核包含一组可学习的权重参数。无论卷积核滑动到图像的哪个位置，它所使用的权重都是相同的。

    参数共享带来了两个关键优势：

    1.  [cite_start]**大幅减少模型参数量:** 在一个全连接网络中，如果输入一张1000x1000的图像，第一个隐藏层的每个神经元都需要与全部100万个像素点连接，导致参数数量极其庞大 [cite: 110][cite_start]。而在CNN中，参数数量仅与卷积核的大小有关，而与输入图像的大小无关。例如，一个5x5的卷积核只需要25个参数。这种设计使得训练深层网络成为可能 。

    2.  **平移等变性 (Translation Equivariance):** 由于同一个卷积核在整个图像上扫描，它能够检测到特定模式（如边缘、角点），而不管这个模式出现在图像的哪个位置。如果一个模式在图像左上角能被检测到，那么当它出现在右下角时，同样的卷积核也能检测到它。这种特性对于图像识别等任务至关重要，因为目标物体可能出现在图像的任何地方。